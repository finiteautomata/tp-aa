{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Aprendizaje Automático\n",
    "\n",
    "# Trabajo Práctico 1 - Detección de Spam\n",
    "\n",
    "# Estudiantes: Juan Manuel Perez, Mariela Rajngewerc, Tomás Freilij\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ayudas para nosotros\n",
    "\n",
    "# https://sourceforge.net/p/jupiter/wiki/markdown_syntax/#md_ex_text\n",
    "\n",
    "\n",
    " PREGUNTA: ¿Cómo debe ser el informe?\n",
    "\n",
    "RESPUESTA: Recomendamos armar el informe con las siguientes secciones:\n",
    "\n",
    "    Extracción de atributos: Describir en castellano los atributos extraidos de los mails, en forma concisa.\n",
    "    Modelos: Listar los algoritmos de aprendizaje elegidos para experimentar. Describir cualquier decisión que hayan tomado (p.ej., elección de hiperparámetros).\n",
    "    Reducción de dimensionalidad: Describir brevemente las técnicas empleadas.\n",
    "    Resultados: Describir los resultados conseguidos por los distintos modelos y conjuntos de atributos considerados. Preferentemente, resumir los resultados en tablas/figuras. Mencionar los tiempos de ejecución aproximados de cada técnica.\n",
    "    Discusión: Analizar los resultados, buscando responder cuestiones como, por ejemplo: ¿cuáles son los atributos encontrados con mayor poder predictivo?, ¿cuán sensibles fueron los algoritmos a las técnicas de reducción de dimensionalidad consideradas?, ¿resultó clara la elección del algoritmo para la competencia, o hubo que poner en la balanza distintos factores?\n",
    "\n",
    "La longitud sugerida del informe es de entre 3 y 5 páginas de texto (sin contar tablas o figuras). Además pueden incluirse tablas y figuras, pero siempre deben ser referenciadas y explicadas en el texto.\n",
    "\n",
    "Si se tomaron ideas de la literatura (papers, libros, blogs, wikipedia o lo que sea), citar claramente las fuentes (autor, título, tipo de publicación, año de publicación, URL si corresponde, etc.).\n",
    "\n",
    "No incluir código. Si es necesario describir un algoritmo, hacerlo en pseudocódigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen del trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El trabajo tuvo como punto central poder probar los distintos clasificadores pedidos por la cátedra, con las respectivas mejoras que se les pueda encontrar a cada uno. Las implementaciones usadas fueron las provistas por Scikit-Learn.\n",
    "\n",
    "En términos generales, el esquema fue correr los clasificadores obteniendo distintas hipótesis según los hiperparámetros que podíamos modificar.\n",
    "\n",
    "Luego se intentó encontrar la mejor opción. Para esto se usaron dos implementaciones de la librería, GridSearch y RandomizedSearch. La primera obtiene la mejor haciendo una búsqueda exhaustiva, pero resultó ser bastante costosa en términos de tiempos de ejecución. Por esto último optamos por RandomizedSearch, que si bien no garantiza encontrar la óptima, provee un buen trade-off entre tiempos y resultados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Atributos\n",
    "\n",
    "Los atributos principales que se extrajeron de los mails fueron:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación utilizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Utilizamos 10 fold cross-validation implementada por scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los hiperparámetros que nos parecieron interesantes, provistos por la librería fueron.\n",
    "\n",
    "** Criterio de partición ('criterion')** \n",
    "\n",
    "Establece la función que mide la calidad de una partición de los nodos del árbol. \n",
    "Existen dos provistos por la librería, \"Gini\" y \"Entropía\". El último responde al Information Gain visto en la materia.\n",
    "\n",
    "**Profundidad máxima ('max_depth')**\n",
    "\n",
    "Permite hacer una poda sobre el árbol. \n",
    "\n",
    "**Splitter**\n",
    "\n",
    "Tiene dos opciones, best y random. Establece si se utiliza el mejor criterio de partición o usa un mecanismo aleatorio para buscarlo. Como ya dijimos antes, la calidad de la partición estará dada por el hiperparámetro 'criterion'\n",
    "\n",
    "**Subconjunto de valores de un atributo('max_features')**\n",
    "\n",
    "Establece el máximo de valores de un atributo que se tiene en cuenta. Visto más gráficamente, establece el ancho del árbol.\n",
    "Se puede establecer un número fijo, o un porcentaje, entre otras posibilidades.\n",
    "\n",
    "**Criterio de corte para un nodo('min_samples_split')**\n",
    "\n",
    "La mínima cantidad de muestras necesarias para que se justifique la partición en un nodo. \n",
    "\n",
    "\n",
    "** La mejor combinación de hiperparámetros fue **\n",
    "\n",
    "'min_samples_split' = 82 \n",
    "\n",
    "'splitter' = 'best' \n",
    "\n",
    "'criterion' = 'entropy' \n",
    "\n",
    "'max_depth'= 18 \n",
    "\n",
    "'max_features' = 0.90000000000000013\n",
    "\n",
    "El valor fue 0.987803482259 con el scoring roc_auc.\n",
    "\n",
    " \n",
    "# VER QUE ONDA CON EL ROC AUC SCORE QUE VARIA CON EL ANTERIOR MOSTRADO \n",
    "\n",
    "\n",
    "| precision_score | accuracy_score   |    f1_score \t| recall_score |\troc_auc_score |\n",
    "|-----------------|------------------|--------------|--------------|------------------|\n",
    "| 0.956531        | 0.957444         |    0.957487 \t|  0.958444    |     0.957444     |\n",
    "\n",
    "\n",
    "\n",
    " \t   \t\n",
    "\n",
    " \t             \t    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la naturaleza del clasificador, hay que tener también en cuenta la distribución de las muestras. En ese sentido, la librería provee tres clasificadores de Naive Bayes, usando una distribución Gaussiana, una de Bernoulli y una Multinomial.\n",
    "\n",
    "Las primeras pruebas arrojaron resultados nulos con la multinomial y la de bernoulli. Cuando hablamos de resultados nulos nos referimos a que, con pruebas varias que hacíamos, la clasificación era completamente errada.\n",
    "\n",
    "Dado que la Gaussiana no arrojaba ese tipo de resultado, decidimos trabajar con esa propuesta.\n",
    "\n",
    "Ahora bien, cuando graficábamos la distribución de algunos atributos en los mails veíamos que se parecía más a una Exponencial que a una Gaussiana. Además, los gráficos perdían proporcionalidad y no se podían entender. Al intentar aplicarle logaritmo a los datos para darle otra escala vimos que tomaban una forma de campa de gauss.\n",
    "\n",
    "Como además aplicar el logaritmo preserva las desigualdades, nos parecía razonable usar esta conversión previa para trabajar con el clasificador.\n",
    "\n",
    "Este clasificador no tiene parámetros así que no tuvimos que hacer pruebas variadas en relación a modificación de hiperparámetros.\n",
    "\n",
    "Los resultados obtenidos sin previa normalización usando logaritmo fueron:\n",
    "\n",
    " |\tprecision_score  | accuracy_score  |\tf1_score  |\trecall_score  |\troc_auc_score | \n",
    " |-------------------|-----------------|--------------|---------------|---------------|  \n",
    " |\t0.504766 \t     |0.509222 \t       |    0.665556  |\t0.976667 \t  | 0.509222      |  \n",
    " \n",
    " Con normalización fueron:\n",
    " \n",
    "| precision_score |\taccuracy_score | f1_score |\trecall_score | roc_auc_score |\n",
    "|-----------------|----------------|----------|--------------|---------------|\n",
    "| 1.0 \t          | 0.500778 \t   | 0.003106 |\t0.001556 \t |  0.500778     |            \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGREGAR LO DE BERNOULLI QUE APARECIÓ DESPUÉS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
