{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboles de Decisión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80993, 273)\n"
     ]
    }
   ],
   "source": [
    "# Esto agrega al python path el directorio ..\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import config\n",
    "from helpers import get_scores\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from transformers import transformer\n",
    "from data_builder import load_test_data, load_dev_data, load_small_dev_data\n",
    "\n",
    "df, target = load_dev_data()\n",
    "X = transformer.fit_transform(df)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros\n",
    "\n",
    "Busquemos los mejores (posibles) hiperparámetros\n",
    "\n",
    "Para eso, primero veamos qué hiperparámetros nos provee la implementación de SKLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Algunas observaciones previas:\n",
    "\n",
    "El árbol que se genera no es usando ID3 sino CART. Una pequeña introducción\n",
    "se puede ver en\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart\n",
    "\n",
    "No está muy completo el asunto ahí, habría que hurgar algún paper extra\n",
    "\n",
    "Opciones:\n",
    "\n",
    "- criterion: gini o entropy. Son dos medidas distintas\n",
    "- splitter: No estoy muy seguro\n",
    "- max_depth: máxima profundidad del árbol\n",
    "- max_features: qué porcentaje de variables tomo a la hora de partir un nodo.\n",
    "  Estas variables se eligen aleatoriamente\n",
    "- min_samples_split: cuántos elementos tengo que tener en un nodo para decidir\n",
    "  partirlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 49.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 62.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 76.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 94.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 111.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 132.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 150.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 154.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'min_samples_split': 92, 'splitter': 'best', 'criterion': 'entropy', 'max_depth': 50, 'max_features': 0.59999999999999998}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.965289</td>\n",
       "      <td>0.967667</td>\n",
       "      <td>0.967749</td>\n",
       "      <td>0.970222</td>\n",
       "      <td>0.967667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision_score  accuracy_score  f1_score  \\\n",
       "DecisionTreeClassifier         0.965289        0.967667  0.967749   \n",
       "\n",
       "                        recall_score  roc_auc_score  \n",
       "DecisionTreeClassifier      0.970222       0.967667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from search import find_best_classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "options = {\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_features': np.arange(0.1, 1.0, 0.1),\n",
    "    'min_samples_split': range(2, 102, 10),\n",
    "}\n",
    "\n",
    "search_options = {\n",
    "    'cv': 10,\n",
    "    'scoring': 'roc_auc',\n",
    "    'n_jobs': -1,\n",
    "    'n_iter': 1000,\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(DecisionTreeClassifier(), options, verbose=1, **search_options)\n",
    "\n",
    "search.fit(X, target)\n",
    "\n",
    "print(\"Mejores parámetros: {}\".format(search.best_params_))\n",
    "\n",
    "get_scores(search.best_estimator_, transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Haciendo PCA\n",
    "\n",
    "\n",
    "Probemos ahora haciendo PCA sobre las variables, y luego aplicando el clasificador.\n",
    "\n",
    "La reducción de dimensionalidad será una variable más del proceso de búsqueda de parámetros. Nos quedamos sólo con las variables de mayor componente principal. No sé si necesariamente es lo mejor esto..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(copy=True, n_components=None, whiten=False)), ('tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('tree', DecisionTreeClassifier()),\n",
    "])\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso todas las opciones anteriores de árboles, pero tengo que agregarle un prefijo porque los meto en un pipeline (prefijo `tree__` para opciones del árbol, `pca__` para las de pca)\n",
    "\n",
    "Voy a tomar como posibles dimensiones 20, 30, ..., n_dims - 10, n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 100.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 144.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 195.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 252.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 318.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 391.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 472.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 573.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 670.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 768.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 785.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'tree__criterion': 'entropy', 'tree__splitter': 'best', 'tree__min_samples_split': 92, 'pca__n_components': 100, 'tree__max_features': 0.80000000000000004, 'tree__max_depth': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline</th>\n",
       "      <td>0.945659</td>\n",
       "      <td>0.948333</td>\n",
       "      <td>0.948488</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>0.948333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision_score  accuracy_score  f1_score  recall_score  \\\n",
       "Pipeline         0.945659        0.948333  0.948488      0.951333   \n",
       "\n",
       "          roc_auc_score  \n",
       "Pipeline       0.948333  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import add_prefix\n",
    "\n",
    "new_options = add_prefix(options, 'tree__')\n",
    "\n",
    "no_features = X.shape[1]\n",
    "\n",
    "new_options.update({\n",
    "    'pca__n_components' : range(20, no_features, 10)\n",
    "})\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(clf, new_options, verbose=1, **search_options)\n",
    "\n",
    "search.fit(X, target)\n",
    "\n",
    "print(\"Mejores parámetros: {}\".format(search.best_params_))\n",
    "\n",
    "get_scores(search.best_estimator_, transformer)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
