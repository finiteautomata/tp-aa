{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Aprendizaje Automático\n",
    "\n",
    "# Trabajo Práctico 1 - Detección de Spam\n",
    "\n",
    "# Estudiantes: Juan Manuel Perez, Mariela Rajngewerc, Tomás Freilij\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ayudas para nosotros\n",
    "\n",
    "# https://sourceforge.net/p/jupiter/wiki/markdown_syntax/#md_ex_text\n",
    "\n",
    "\n",
    " PREGUNTA: ¿Cómo debe ser el informe?\n",
    "\n",
    "RESPUESTA: Recomendamos armar el informe con las siguientes secciones:\n",
    "\n",
    "    Extracción de atributos: Describir en castellano los atributos extraidos de los mails, en forma concisa.\n",
    "    Modelos: Listar los algoritmos de aprendizaje elegidos para experimentar. Describir cualquier decisión que hayan tomado (p.ej., elección de hiperparámetros).\n",
    "    Reducción de dimensionalidad: Describir brevemente las técnicas empleadas.\n",
    "    Resultados: Describir los resultados conseguidos por los distintos modelos y conjuntos de atributos considerados. Preferentemente, resumir los resultados en tablas/figuras. Mencionar los tiempos de ejecución aproximados de cada técnica.\n",
    "    Discusión: Analizar los resultados, buscando responder cuestiones como, por ejemplo: ¿cuáles son los atributos encontrados con mayor poder predictivo?, ¿cuán sensibles fueron los algoritmos a las técnicas de reducción de dimensionalidad consideradas?, ¿resultó clara la elección del algoritmo para la competencia, o hubo que poner en la balanza distintos factores?\n",
    "\n",
    "La longitud sugerida del informe es de entre 3 y 5 páginas de texto (sin contar tablas o figuras). Además pueden incluirse tablas y figuras, pero siempre deben ser referenciadas y explicadas en el texto.\n",
    "\n",
    "Si se tomaron ideas de la literatura (papers, libros, blogs, wikipedia o lo que sea), citar claramente las fuentes (autor, título, tipo de publicación, año de publicación, URL si corresponde, etc.).\n",
    "\n",
    "No incluir código. Si es necesario describir un algoritmo, hacerlo en pseudocódigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen del trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El trabajo tuvo como punto central poder probar los distintos clasificadores pedidos por la cátedra, con las respectivas mejoras que se les pueda encontrar a cada uno. Las implementaciones usadas fueron las provistas por Scikit-Learn.\n",
    "\n",
    "En términos generales, el esquema fue correr los clasificadores obteniendo distintas hipótesis según los hiperparámetros que podíamos modificar.\n",
    "\n",
    "Luego se intentó encontrar la mejor opción. Para esto se usaron dos implementaciones de la librería, GridSearch y RandomizedSearch. La primera obtiene la mejor haciendo una búsqueda exhaustiva, pero resultó ser bastante costosa en términos de tiempos de ejecución. Por esto último optamos por RandomizedSearch, que si bien no garantiza encontrar la óptima, provee un buen trade-off entre tiempos y resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los hiperparámetros que nos parecieron interesantes, provistos por la librería fueron.\n",
    "\n",
    "** Criterio de partición ('criterion')** \n",
    "\n",
    "Establece la función que mide la calidad de una partición de los nodos del árbol. \n",
    "Existen dos provistos por la librería, \"Gini\" y \"Entropía\". El último responde al Information Gain visto en la materia.\n",
    "\n",
    "**Profundidad máxima ('max_depth')**\n",
    "\n",
    "Permite hacer una poda sobre el árbol. \n",
    "\n",
    "**Splitter**\n",
    "\n",
    "Tiene dos opciones, best y random. Establece si se utiliza el mejor criterio de partición o usa un mecanismo aleatorio para buscarlo. Como ya dijimos antes, la calidad de la partición estará dada por el hiperparámetro 'criterion'\n",
    "\n",
    "**Subconjunto de valores de un atributo('max_features')**\n",
    "\n",
    "Establece el máximo de valores de un atributo que se tiene en cuenta. Visto más gráficamente, establece el ancho del árbol.\n",
    "Se puede establecer un número fijo, o un porcentaje, entre otras posibilidades.\n",
    "\n",
    "**Criterio de corte para un nodo('min_samples_split')**\n",
    "\n",
    "La mínima cantidad de muestras necesarias para que se justifique la partición en un nodo. \n",
    "\n",
    "\n",
    "** La mejor combinación de hiperparámetros fue **\n",
    "\n",
    "'min_samples_split' = 82 \n",
    "\n",
    "'splitter' = 'best' \n",
    "\n",
    "'criterion' = 'entropy' \n",
    "\n",
    "'max_depth'= 18 \n",
    "\n",
    "'max_features' = 0.90000000000000013\n",
    "\n",
    "El valor fue 0.987803482259 con el scoring roc_auc.\n",
    "\n",
    " \n",
    "# VER QUE ONDA CON EL ROC AUC SCORE QUE VARIA CON EL ANTERIOR MOSTRADO \n",
    "\n",
    "\n",
    "| precision_score | accuracy_score   |    f1_score \t| recall_score |\troc_auc_score |\n",
    "|-----------------|------------------|--------------|--------------|------------------|\n",
    "| 0.956531        | 0.957444         |    0.957487 \t|  0.958444    |     0.957444     |\n",
    "\n",
    "\n",
    "\n",
    " \t   \t\n",
    "\n",
    " \t             \t    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
