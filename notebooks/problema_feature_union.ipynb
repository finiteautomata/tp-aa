{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "Vamos a hacer Tf-Idf sobre nuestros datos. Primero, boiler-plate canónico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.debugger import Tracer\n",
    "# Esto agrega al python path el directorio ..\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import config\n",
    "from data_builder import load_test_data, load_dev_data, load_small_dev_data\n",
    "\n",
    "\n",
    "df, target = load_small_dev_data()\n",
    "\n",
    "options = {\n",
    "    'max_features': 100,\n",
    "    'ngram_range': (1, 1),\n",
    "    'min_df': 0.001,\n",
    "    'max_df': 0.75,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  from: \"edwina dotson\" <iofigcodgojmqs#####>\\r\\...   \n",
      "1  Received: from nahou-mscnx06p.corp.enron.com (...   \n",
      "\n",
      "                                             payload  \n",
      "0  <!doctype html public \"-//w3c//dtd html 3.2//e...  \n",
      "1    Dear icruise Member, \\nICRUISE SPECIALS FOR ...  \n",
      "(8099, 2)\n",
      "(8099,)\n"
     ]
    }
   ],
   "source": [
    "print df.iloc[:2]\n",
    "\n",
    "print df.shape\n",
    "print target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Union\n",
    "\n",
    "Hagamos el feature extractor a ver qué onda..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('len', LenTransformer()), ('spaces', SpaceTransformer())],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "class BaseTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Clase base para todos nuestros transformers.\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        u\"\"\"Este método no hace nada, pero debe estar.\"\"\"\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "class LenTransformer(BaseTransformer):\n",
    "    \"\"\"Clase que agrega len al dataframe.\"\"\"\n",
    "\n",
    "    def transform(self, data):\n",
    "        u\"\"\"Aplica la transformación.\"\"\"\n",
    "        return np.array(data.apply(len))\n",
    "\n",
    "\n",
    "class SpaceTransformer(BaseTransformer):\n",
    "    \"\"\"Clase que agrega len al coso este.\"\"\"\n",
    "\n",
    "    def transform(self, data):\n",
    "        u\"\"\"Aplica la transformación.\"\"\"\n",
    "        return np.array(data.apply(\n",
    "            lambda t: t.count(' ')\n",
    "        ))\n",
    "\n",
    "\n",
    "my_extr = FeatureUnion([\n",
    "    ('len', LenTransformer()),\n",
    "    ('spaces', SpaceTransformer()),\n",
    "    #('tfidf', TfidfVectorizer(max_features=100))\n",
    "])\n",
    "\n",
    "my_extr.fit(df.payload, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = my_extr.transform(df.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16198,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
